---
title: "Project Plan and EDA"
format:
    html:
        embed-resources: true
editor: visual
---

**Reading CSV**

```{r readingCSV}
fulldata <- read.csv("alzheimers_disease_data.csv")
fulldata$Diagnosis <- factor(fulldata$Diagnosis, levels = c(0, 1), labels = c("No", "Yes"))
str(fulldata)
```

On checking for NAs in the data, we found the result to be `r anyNA(fulldata)`.

**Dropping columns**

```{r dropcolumns}
fulldata <- subset(fulldata, select = -c(PatientID, DoctorInCharge))
```

**Tree Model**

```{r tree}
library(tree)
treemodel <- tree(Diagnosis ~ ., data = fulldata)
plot(treemodel)
text(treemodel)
```

**Cross Validation Model**

```{r CVModel, message=FALSE}
library(class)
library(caret)

set.seed(5003)
kfolds <- createFolds(fulldata$Diagnosis, k = 10)
create_training_and_test <- function(index, data) {
  train_data <- data[-index, ]
  test_data <- data[index, ]
  list(training = train_data, test = test_data)
}
kfold_training_and_test <- lapply(kfolds, create_training_and_test, data = fulldata)

fit_knn_and_reports_obs_and_pred <- function(data_list, k = 5) {
  train_data <- data_list[["training"]]
  test_data <- data_list[["test"]]
  train_arg <- train_data[ , -which(names(train_data) == "Diagnosis")] 
  test_arg <- test_data[ , -which(names(test_data) == "Diagnosis")] 
  cl_arg <- train_data[ ,"Diagnosis"]
  model <- knn(
    train = train_arg,
    test = test_arg,
    cl = cl_arg,
    k = k)
  list(observed = test_data[ , "Diagnosis"], predicted = model)
}
obs_and_pred <- lapply(kfold_training_and_test, fit_knn_and_reports_obs_and_pred)


performance_calcs <- function(obs_and_pred) {
  actual <- obs_and_pred[["observed"]]
  predicted <- obs_and_pred[["predicted"]]
  CM <- confusionMatrix(actual, predicted)
  CMtab <- CM$table
}
CMtablelist <- lapply(obs_and_pred, performance_calcs)
perform_measures_func <- function(CMtablelist) {
  Consol_CMtable <- Reduce(`+`, CMtablelist)
  Consol_CM <- confusionMatrix(Consol_CMtable)
  Sensit <- Consol_CM$byClass[["Sensitivity"]]
  Specif <- Consol_CM$byClass[["Specificity"]]
  Accura <- Consol_CM$overall[["Accuracy"]]
  TP <- Consol_CM$table["No", "No"]
  FP <- Consol_CM$table["No", "Yes"]
  FN <- Consol_CM$table["Yes", "No"]
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * (precision * recall) / (precision + recall)
  Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- perform_measures_func(CMtablelist)
perf_measures
```

## Overview of the Problem

In our project, using anonymised patient information, medical history, cognitive and functional assessments, and several other factors, we intend to create a right sized model with adequate performance to diagnose if the patient has Alzheimer's or not - binary classification.

According to Alzheimer's association, 1 in 3 older adult dies with Alzheimer's or another form of dementia. It kills more people than breast and prostate cancer combined. These statistics suggest that we have or will encounter people in our lives who suffer from some form of dementia. To date, the exact cause of Alzheimer's is not fully understood, but researchers have identified that vascular, genetics, and lifestyle & environmental factors contribute to its development. Therefore, early detection is critical to treat or prevent Alzheimer's. The ability to identify, detect and prevent, is crucial to sustain growing aging population in our societies. We believe our model can be the foundation to help people with early detection and intervention, and for governments to reduce the cost burden on Medicare.

## Alhzeimer's Disease Dataset

There are **`r nrow(fulldata)`** observations and **`r ncol(fulldata)`** variables in this dataset, of which **`r (ncol(fulldata)-1)`** are independent variables and **'1'** is the target variable. The table below provides a breakdown of these variables.

```{r, data_description, fold: true}

# read the data from a CSV file and display it as a table 

# Load required libraries
library(readr)   # To read CSV files
library(knitr)   # To format tables in a nice layout

# Read the CSV file into a dataframe
data <- read_csv("dataset_description.csv", show_col_types = FALSE)


# Display the entire dataset as a table
kable(data)
```

## Clear description of potential challenges

**1. Class imbalance:** As depicted in the previous section, our dataset is not balanced and we have more observations on negative diagnosis than positive. This can inadvertently introduce bias in our model. To address the imbalance, we will test models that offset the imbalance through randomness and cross validation.

**2. Feature selection:** To choose the adequate number of features out of the 33 available, it will require us to deploy and test several feature selection techniques find the right model size. But our group also has extensive medical data experience to test the statistical selections against intuition.

**3. Synthetic data:** The provenance of the data suggests it was generated synthetically. The data was generated for academic purposes with distributions that may mimic the real world. But we don't have unseen real world data to validate the model. This means the model should be used cautiously in the real world, given the medical context.

**4. Limited observations:** Our dataset contains 2149 observations, which is just sufficiently large to train and test our model. But it is not large enough to qualify has well-tested models in medical context. However, using the models suggested to address class imbalance will also help us train and tune our model for better performance.

## Performance metrics

## Models chosen

We plan to create multiple models and test the performance to find the best model. As we have

## Plan or schedule

```{r, schedule}
# Install and load the required package
install.packages("png")
library(png)

# Load the PNG image
img <- readPNG("schedule.png")

# Create an empty plot
plot(1:2, type = "n", xlab = "", ylab = "", axes = FALSE)

# Display the image
rasterImage(img, 1, 1, 2, 2)

```
