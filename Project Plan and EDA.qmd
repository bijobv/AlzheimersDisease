---
title: "Project Plan and EDA"
author: "Bijo Varghese, Hong Fu, Jessica Kentwell"
date: "`r format(Sys.Date(), '%B %d, %Y')`" # current date using r 
format:
    html:
        embed-resources: true
editor: visual
---

```{r readingCSV, echo=FALSE}
fulldata <- read.csv("alzheimers_disease_data.csv")
fulldata$Diagnosis <- factor(fulldata$Diagnosis, levels = c(0, 1), labels = c("No", "Yes"))
fulldata <- subset(fulldata, select = -c(PatientID, DoctorInCharge))
```

## Overview of the Problem

In our project, using anonymised patient information, medical history, cognitive and functional assessments, and several other factors, we intend to create a right sized model with adequate performance to diagnose if the patient has Alzheimer's or not - binary classification.

According to Alzheimer's association, 1 in 3 older adult dies with Alzheimer's or another form of dementia. It kills more people than breast and prostate cancer combined. These statistics suggest that we have or will encounter people in our lives who suffer from some form of dementia. To date, the exact cause of Alzheimer's is not fully understood, but researchers have identified that vascular, genetics, and lifestyle & environmental factors contribute to its development. Therefore, early detection is critical to treat or prevent Alzheimer's. The ability to identify, detect and prevent, is crucial to sustain growing aging population in our societies. We believe our model can be the foundation to help people with early detection and intervention, and for governments to reduce the cost burden on Medicare.

## Alhzeimer's Disease Dataset

There are **`r nrow(fulldata)`** observations and **`r ncol(fulldata)`** variables in this dataset, of which **`r (ncol(fulldata)-1)`** are independent variables and **'1'** is the target variable. The table below provides a breakdown of these variables.

```{r, data_description, fold: true, echo=FALSE}

# Load required libraries
library(readr)   # To read CSV files
library(knitr)   # To format tables in a nice layout
library(kableExtra)

# Read the CSV file into a dataframe
data <- read_csv("dataset_description.csv", show_col_types = FALSE)

kable(data, format = "html") %>%
  kable_styling() %>%
  column_spec(1:ncol(data), extra_css = "font-size: 11px;") %>%  # Font size for table body
  row_spec(0, extra_css = "font-size: 11px;")  # Font size for headers (row 0)
```

## Clear description of potential challenges

1.  **Class imbalance:** As depicted in the previous section, our dataset is not balanced and we have more observations on negative diagnosis than positive. This can inadvertently introduce bias in our model. To address the imbalance, we will test models that offset the imbalance through randomness and cross validation.
2.  **Feature selection:** To choose the adequate number of features out of the 33 available, it will require us to deploy and test several feature selection techniques find the right model size. But our group also has extensive medical data experience to test the statistical selections against intuition.
3.  **Synthetic data:** The provenance of the data suggests it was generated synthetically. The data was generated for academic purposes with distributions that may mimic the real world. But we don't have unseen real world data to validate the model. This means the model should be used cautiously in the real world, given the medical context.
4.  **Limited observations:** Our dataset contains 2149 observations, which is just sufficiently large to train and test our model. But it is not large enough to qualify has well-tested models in medical context. However, using the models suggested to address class imbalance will also help us train and tune our model for better performance.

## Performance metrics

## Models chosen

We plan to create multiple models and compare their performance and size.

1.  **Lasso Logistic Regression:** As we have a binary classification problem, we aim to employ Lasso with Logistic Regression as our base model. It will help us perform feature selection from 33 features, where most of the features are normally distributed, while simulatenously fitting a Logistic Regression model. Given Lasso's ability to shrink the coefficient estimates towards zero, it would help us select the best subset through cross-validation.
2.  **Random Forest:** We also intend to test Random Forest model on our dataset. To address the challenges we face from Class imbalance, Synthetic data and Limited observations, we believe Random Forest could be very useful model to deploy and compare. Even though the model performance would be derived from the forest, we will visualise a single tree as it lends itself to be understood easily and follow along. Especially, in the context of our dataset, where medical practitioners and agencies that may want to understand the scaffolding of our model.
3.  **k-fold kNN Cross-Validation:** Finally, we will also deploy a k-fold kNN Cross-Validation model. Similar to Random Forest, it helps as address similar challenges on Class imbalance, Synthetic data, and Limited observation. Through cross-validation we will be able to tune the k parameter in the kNN model to find the best performing model.



## Proposed Plan \| Schedule

```{r schedule, echo=FALSE}
library(knitr)
include_graphics("schedule.png")
```
